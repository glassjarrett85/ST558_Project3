[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "ST558 Project 3 - Modeling",
    "section": "",
    "text": "Modeling\nThis exploratory analysis will be performed on the Diabetes Health Indicators Data set, available from kaggle.com. (Click here for more information) This is a data set of survey responses to a questionnaire distributed by the CDC. Including the response variable Diabetes_binary, there are 21 additional predictor variables recorded; however, this analysis will review the following variables:\n\n\n\n\n\n\n\nVariable\nDescription of Variable\n\n\n\n\nDiabetes_binary\nThe status of diabetes for the respondent.\nLevels: Not Diabetic, Diabetic or Pre-Diabetic\n\n\nHighChol\nIndicator variable for high cholesterol.\nLevels: Yes, No\n\n\nBMI\nRecorded Body Mass Indices for individuals.\n\n\nHeartDiseaseorAttack\nIndicator variable for whether or not someone has had coronary heart disease (CHD) or myocardial infarction (MI).\nLevels: Yes, No\n\n\nPhysActivity\nIndicator variable capturing if someone has performed physical activity outside of their job within the last 30 days or not.\nLevels: Some, None\n\n\nGenHlth\nA categorical variable self-assessing general level of health.\nLevels: Excellent, Very Good, Good, Fair, Poor\n\n\nPhysHlth\nThe number of days (within the last 30) of any physical injury or illness.\nResponse: Any number between 0 and 30, inclusive.\n\n\nDiffWalk\nAn indicator variable recording any difficulty walking or or climbing up stairs.\nLevels: Yes, No\n\n\nSex\nThe sex of the respondent.\nLevels: Male, Female\n\n\nAge\nFive-year ranges of ages, into which the respondent is categorized.\nLevels: 18-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59, 60-64, 65-69, 70-74, 75-79, 80+, or Not given.\n\n\n\nIn order to perform modeling on this data set, this will be split into a 70/30 training and a test data sets, stratified on the Diabetic_binary indicator variable.\n\n# The libraries and data frame are housed in helper.R file.\nsource(\"helper.R\")\n\n# The data set has been re-read in, under the name `df`\n# Data will be split 70/30 to training and test sets.\nsplit &lt;- initial_split(data=df, prop=0.7, strata=Diabetes_binary)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\n\nThe models will be evaluated using log-loss with 5-fold cross-validation. The model will be selected on the basis of lowest log-loss.\n\ntrain_5fold &lt;- vfold_cv(train, v=5, strata=Diabetes_binary)\n\n\nClassification Tree\nA classification tree is a means of modeling a classification task, to predict which category (class) a predicted value should be sorted into. The data set is split iteratively, beginning with the Root node (entire data set), with rules at each level (decision nodes) to maximize homogeneity of the child nodes.\n\n# Generate a grid for tuning\ntreeGrid &lt;- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)\n\n# Establish the Classification Tree engine\ntreeEngine &lt;- decision_tree(\n  cost_complexity=tune(),\n  tree_depth=tune(),\n  min_n=tune()\n) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n# Generate the Workflow object\ntreeWkfl &lt;- workflow() |&gt;\n  add_model(treeEngine) |&gt;\n  add_formula(Diabetes_binary ~ .)\n\n# Now tuning the model\ntreeTuned &lt;- treeWkfl |&gt;\n  tune_grid(resamples=train_5fold,\n            grid=treeGrid,\n            metrics=metric_set(mn_log_loss))\n\n# The best result\ntreeTuned |&gt; show_best(metric=\"mn_log_loss\", n=1)\n\n# A tibble: 1 × 9\n  cost_complexity tree_depth min_n .metric     .estimator  mean     n  std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;\n1    0.0000000001         11    30 mn_log_loss binary     0.333     5 0.000579\n# ℹ 1 more variable: .config &lt;chr&gt;\n\n# And the Workflow with the best parameters:\ntreeBest &lt;- treeWkfl |&gt;\n  finalize_workflow(treeTuned |&gt; select_best(metric=\"mn_log_loss\"))\n\n# Finally, evaluate this optimized model on the entire Training set, and apply to predictions to the Test set.\ntreeFinal &lt;- treeBest |&gt;\n  fit(data=train) |&gt;\n  extract_fit_engine()\n\n# The plot for the classification tree\nlibrary(rpart.plot)\n\nLoading required package: rpart\n\n\n\nAttaching package: 'rpart'\n\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nrpart.plot(treeFinal, roundint=FALSE, type=1, extra=1, tweak=1.2, main=\"Optimized Classification Tree\")\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\n\n\n# Additionally collect the metrics from the model run on the Test set\ntreeMets &lt;- treeBest |&gt; \n  last_fit(split, metrics=metric_set(mn_log_loss)) |&gt;\n  collect_metrics()\ntreeMets\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary         0.330 pre0_mod0_post0\n\n\n\n\nRandom Forest\nA Random Forest model is a non-parametric learning method that can be used for classification modeling. It works by building a large number of individual, high-variance decision trees on bootstrap samples of the training data. The bootstrap samples are made by taking samples (with replacement) of the training data. At each node split during the construction of these trees, a random subset of predictors is considered. This combination of bagging (sampling data) and feature randomness (sampling features) ensures that the resulting trees are highly uncorrelated. For a categorical prediction task (classification), the final output is determined by majority voting, where the category chosen by the most individual trees becomes the forest’s final prediction, effectively reducing the model’s overall variance and leading to high accuracy and robustness against overfitting.\n\n# Utilize the same `split`, `train`, `test`, and `train_5fold` variables as above.\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.3.3\n\nrfEngine &lt;- rand_forest(\n  mtry=tune(),\n  min_n=tune(),\n  trees=100 \n) |&gt;\n  set_engine(\"ranger\", importance=\"impurity\") |&gt;\n  set_mode(\"classification\")\n\n# Generate the workflow based on the RF engine specified above\nrfWkfl &lt;- workflow() |&gt;\n  add_model(rfEngine) |&gt;\n  add_formula(Diabetes_binary ~ .)\n\n# Perform tuning. The seed was already set above.\nrfTuned &lt;- rfWkfl |&gt;\n  tune_grid(resamples=train_5fold,\n            metrics=metric_set(mn_log_loss),\n            control=control_grid(save_pred=TRUE)\n  )\n\ni Creating pre-processing data to finalize 1 unknown parameter: \"mtry\"\n\n# The top performing models based on log-loss\nrfTuned |&gt; show_best(metric=\"mn_log_loss\", n=5)\n\n# A tibble: 5 × 8\n   mtry min_n .metric     .estimator  mean     n  std_err .config         \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;           \n1     2     2 mn_log_loss binary     0.324     5 0.000609 pre0_mod03_post0\n2     3    18 mn_log_loss binary     0.325     5 0.000643 pre0_mod04_post0\n3     4    35 mn_log_loss binary     0.328     5 0.000710 pre0_mod05_post0\n4     1    31 mn_log_loss binary     0.341     5 0.000246 pre0_mod02_post0\n5     1    14 mn_log_loss binary     0.341     5 0.000834 pre0_mod01_post0\n\n# And the Workflow with the best parameters:\nrfBest &lt;- rfWkfl |&gt;\n  finalize_workflow(rfTuned |&gt; select_best(metric=\"mn_log_loss\"))\n\n# Finally, evaluate this optimized model on the entire Training set, and apply to predictions to the Test set.\nrfFinal &lt;- rfBest |&gt;\n  fit(data=train) |&gt;\n  extract_fit_engine()\n\n# Demonstration of the change in mn_log_loss across different tuning parameters\nrfTuned |&gt;\n  autoplot() +\n  geom_smooth(se=FALSE) +\n  labs(title=\"Log Loss across Random Forest Tuning\",\n       subtitle=\"Across 5-Fold Cross Validation\",\n       y=\"Mean Negative Log Loss (mn_log_loss)\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Collect the metrics from the model run on the Test set\nrfMets &lt;- rfBest |&gt; \n  last_fit(split, metrics=metric_set(mn_log_loss)) |&gt;\n  collect_metrics()\nrfMets\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config        \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 mn_log_loss binary         0.322 pre0_mod0_post0\n\n\n\n\nFinal Model Selection\nNow that the two models have been completed, the mn_log_loss variable can be compare to show which model is a better fit for predicting the data.\n\n\n                Model mn_log_loss\n1 Classification Tree   0.3295410\n2       Random Forest   0.3215061\n\n\nThe metrics indicate here that the Random Forest model produces less loss of fidelity, and has more predictive power than the Classification Tree model. The optimum tuning parameters, taken from above, are\n\nrfTuned |&gt; select_best(metric=\"mn_log_loss\")\n\n# A tibble: 1 × 3\n   mtry min_n .config         \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;           \n1     2     2 pre0_mod03_post0\n\n# Saving the `split` and `rfBest` variables for use with the API.\nsaveRDS(split, \"split.rds\")\nsaveRDS(rfBest, \"rfBest.rds\")\n\nClick here for the EDA page."
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "ST558 Project 3 - EDA",
    "section": "",
    "text": "# Required libraries and data sets are housed in helper.R for consistency across each page.\nsource(\"helper.R\")"
  },
  {
    "objectID": "EDA.html#introduction",
    "href": "EDA.html#introduction",
    "title": "ST558 Project 3 - EDA",
    "section": "Introduction",
    "text": "Introduction\nThis exploratory analysis will be performed on the Diabetes Health Indicators Data set, available from kaggle.com. (Click here for more information) This is a data set of survey responses to a questionnaire distributed by the CDC. Including the response variable Diabetes_binary, there are 21 additional predictor variables recorded; however, this analysis will review the following variables:\n\n\n\n\n\n\n\nVariable\nDescription of Variable\n\n\n\n\nDiabetes_binary\nThe status of diabetes for the respondent.\nLevels: Not Diabetic, Diabetic or Pre-Diabetic\n\n\nHighChol\nIndicator variable for high cholesterol.\nLevels: Yes, No\n\n\nBMI\nRecorded Body Mass Indices for individuals.\n\n\nHeartDiseaseorAttack\nIndicator variable for whether or not someone has had coronary heart disease (CHD) or myocardial infarction (MI).\nLevels: Yes, No\n\n\nPhysActivity\nIndicator variable capturing if someone has performed physical activity outside of their job within the last 30 days or not.\nLevels: Some, None\n\n\nGenHlth\nA categorical variable self-assessing general level of health.\nLevels: Excellent, Very Good, Good, Fair, Poor\n\n\nPhysHlth\nThe number of days (within the last 30) of any physical injury or illness.\nResponse: Any number between 0 and 30, inclusive.\n\n\nDiffWalk\nAn indicator variable recording any difficulty walking or or climbing up stairs.\nLevels: Yes, No\n\n\nSex\nThe sex of the respondent.\nLevels: Male, Female\n\n\nAge\nFive-year ranges of ages, into which the respondent is categorized.\nLevels: 18-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59, 60-64, 65-69, 70-74, 75-79, 80+, or Not given.\n\n\n\nNow that a subset of the original data set has been generated creating only the variables to be analyzed, some summary statistics will be generated for this. The first item to meaningfully evaluate will be whether there are any missing values for any of these variables.\n\n# Confirm the structure of the cleaned data frame\nstr(df)\n\ntibble [253,680 × 10] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary     : Factor w/ 2 levels \"Not diabetic\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 2 2 1 2 2 1 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"None\",\"Some\": 1 2 1 2 2 2 1 2 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"Excellent\",\"Very Good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"No\",\"Yes\": 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"Female\",\"Male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 14 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n\n# Evaluate any missing values across the columns\ndf |&gt;\n  summarize(across(everything(), ~ sum(is.na(.x)))) |&gt;\n  as.data.frame() |&gt;\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiabetes_binary\nHighChol\nBMI\nHeartDiseaseorAttack\nPhysActivity\nGenHlth\nPhysHlth\nDiffWalk\nSex\nAge\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nThis affirms that there are no missing values in our data set. The first interesting item will be to evaluate statistics of the numerical variables:\n\n# Straight statistics of numerical variables\ndf |&gt;\n  summarize(across(where(is.numeric), list(Mean=mean, Median=median, SD=sd), .names=\"{.col}_{.fn}\")) |&gt;\n  pivot_longer(cols=everything(), names_to=\"Variable\", values_to=\"Value\") |&gt;\n  mutate(Variables = word(Variable, 1, sep=\"_\"), Statistic=word(Variable, 2, sep=\"_\")) |&gt;\n  pivot_wider(id_cols=Variables, names_from=Statistic, values_from=Value) |&gt;\n  kable()\n\n\n\n\nVariables\nMean\nMedian\nSD\n\n\n\n\nBMI\n28.382364\n27\n6.608694\n\n\nPhysHlth\n4.242081\n0\n8.717951\n\n\n\n\n# Now split out based on the Diabetes status\ndf |&gt;\n  group_by(Diabetes_binary) |&gt;\n  summarize(across(where(is.numeric), list(Mean=mean, Median=median, SD=sd), .names=\"{.col}_{.fn}\")) |&gt;\n  pivot_longer(cols=BMI_Mean:PhysHlth_SD, names_to=\"Variable\", values_to=\"Value\") |&gt;\n  mutate(Variables = word(Variable, 1, sep=\"_\"), Statistic=word(Variable, 2, sep=\"_\")) |&gt;\n  pivot_wider(id_cols=c(Variables, Diabetes_binary), names_from=Statistic, values_from=Value) |&gt;\n  arrange(Variables)|&gt;\n  kable()\n\n\n\n\nVariables\nDiabetes_binary\nMean\nMedian\nSD\n\n\n\n\nBMI\nNot diabetic\n27.805770\n27\n6.291414\n\n\nBMI\nDiabetic or Pre-diabetic\n31.944011\n31\n7.363401\n\n\nPhysHlth\nNot diabetic\n3.641082\n0\n8.064600\n\n\nPhysHlth\nDiabetic or Pre-diabetic\n7.954479\n1\n11.301490\n\n\n\n\n# Show plots of these variables, to evaluate skewness\nggplot(df, aes(x=BMI, fill=Diabetes_binary, after_stat(density))) +\n  geom_histogram(bins=45) +\n  labs(title=\"Frequency of BMI by Diabetic Status\",\n       x=\"BMI\",\n       y=\"Density\",\n       fill=\"Diabetes Status\")\n\n\n\n\n\n\n\nggplot(df, aes(x=PhysHlth, fill=Diabetes_binary, after_stat(density))) +\n  geom_histogram(bins=45) +\n  labs(title=\"Frequency of BMI by Diabetic Status\",\n       x=\"Number of days (of last 30) with injury or illness\",\n       y=\"Density\",\n       fill=\"Diabetes Status\")  \n\n\n\n\n\n\n\n\nVisual demonstration of the BMI variable indicates slight left-skew, with longer right-tails in diabetic/pre-diabetic participants. Otherwise there is not an obvious ‘tell’ from this graph. The Graph of the PhysHlth variable indicates fairly similar distribution of responses, but there are more reported cases of illness or injury for all 30 days for those with diabetes, than those without.\nClick here for the Modeling page."
  }
]